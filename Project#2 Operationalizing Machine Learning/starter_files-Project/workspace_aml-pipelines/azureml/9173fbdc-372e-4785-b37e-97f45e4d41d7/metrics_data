{"9173fbdc-372e-4785-b37e-97f45e4d41d7_21":{"log_loss":[0.5054303488406625],"average_precision_score_macro":[0.7117310843057969],"recall_score_micro":[0.7380880121396055],"precision_score_weighted":[0.8820810034867883],"average_precision_score_weighted":[0.9213908760771049],"f1_score_micro":[0.7380880121396055],"precision_score_micro":[0.7380880121396055],"recall_score_macro":[0.7459571878698965],"balanced_accuracy":[0.7459571878698965],"weighted_accuracy":[0.7361343086633761],"precision_score_macro":[0.6125421463310443],"accuracy":[0.7380880121396055],"average_precision_score_micro":[0.8333326979055563],"f1_score_macro":[0.6128621761110633],"f1_score_weighted":[0.7837279513111607],"AUC_weighted":[0.8699140682452621],"recall_score_weighted":[0.7380880121396055],"AUC_macro":[0.8699140682452621],"AUC_micro":[0.8387625523566538],"matthews_correlation":[0.3327494542650734],"norm_macro_recall":[0.491914375739793]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_23":{"norm_macro_recall":[0.1906067830329703],"f1_score_weighted":[0.8748210007737296],"log_loss":[0.2557172888343531],"AUC_macro":[0.883227562624225],"AUC_micro":[0.9646265896965328],"recall_score_macro":[0.5953033915164851],"average_precision_score_micro":[0.9658151176833167],"balanced_accuracy":[0.5953033915164851],"f1_score_micro":[0.8995447647951441],"precision_score_micro":[0.8995447647951441],"AUC_weighted":[0.883227562624225],"precision_score_weighted":[0.8809821539667942],"recall_score_micro":[0.8995447647951441],"matthews_correlation":[0.3317121390976068],"accuracy":[0.8995447647951441],"average_precision_score_weighted":[0.9275264136072816],"average_precision_score_macro":[0.7334308656043368],"weighted_accuracy":[0.9750796681903372],"precision_score_macro":[0.7886385822000808],"recall_score_weighted":[0.8995447647951441],"f1_score_macro":[0.628833978973118]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_25":{"log_loss":[0.21046892934872094],"balanced_accuracy":[0.6608085253784868],"precision_score_micro":[0.906525037936267],"f1_score_micro":[0.9065250379362669],"AUC_weighted":[0.9230430103344095],"f1_score_macro":[0.7004312024313583],"f1_score_weighted":[0.8932529870585268],"recall_score_macro":[0.6608085253784868],"average_precision_score_micro":[0.9749534091641618],"weighted_accuracy":[0.9675298014851621],"recall_score_weighted":[0.906525037936267],"precision_score_weighted":[0.8924260904268563],"average_precision_score_weighted":[0.9422752255464003],"matthews_correlation":[0.43190661716695067],"AUC_micro":[0.9737896891643889],"precision_score_macro":[0.7900084518428692],"recall_score_micro":[0.906525037936267],"accuracy":[0.906525037936267],"average_precision_score_macro":[0.7776048420306876],"norm_macro_recall":[0.32161705075697355],"AUC_macro":[0.9230430103344096]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_14":{"AUC_weighted":[0.8523021337527115],"average_precision_score_micro":[0.9577595365660543],"norm_macro_recall":[0.0],"precision_score_macro":[0.4440060698027314],"weighted_accuracy":[0.9843450583187134],"f1_score_weighted":[0.8353395018439429],"recall_score_micro":[0.8880121396054628],"recall_score_macro":[0.5],"average_precision_score_weighted":[0.9165497594234467],"AUC_micro":[0.9580826239232202],"accuracy":[0.8880121396054628],"average_precision_score_macro":[0.7064376323830923],"matthews_correlation":[0.0],"log_loss":[0.2678094746002863],"precision_score_micro":[0.8880121396054628],"f1_score_macro":[0.4703423886834914],"precision_score_weighted":[0.788565560086672],"recall_score_weighted":[0.8880121396054628],"balanced_accuracy":[0.5],"AUC_macro":[0.8523021337527115],"f1_score_micro":[0.8880121396054628]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_29":{"norm_macro_recall":[0.17607951882663064],"weighted_accuracy":[0.9791560627329009],"AUC_macro":[0.9240761734343248],"AUC_weighted":[0.9240761734343247],"balanced_accuracy":[0.5880397594133153],"f1_score_micro":[0.9013657056145675],"average_precision_score_weighted":[0.9443696752272177],"log_loss":[0.2223916449349682],"recall_score_macro":[0.5880397594133153],"recall_score_weighted":[0.9013657056145675],"recall_score_micro":[0.9013657056145675],"precision_score_weighted":[0.887335368424292],"precision_score_macro":[0.822578017890836],"average_precision_score_macro":[0.7866766708012695],"accuracy":[0.9013657056145675],"f1_score_macro":[0.6209921255550848],"f1_score_weighted":[0.8739615130681749],"AUC_micro":[0.9734260536380822],"average_precision_score_micro":[0.9745058880958836],"matthews_correlation":[0.3370441578614488],"precision_score_micro":[0.9013657056145675]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_8":{"precision_score_micro":[0.8892261001517451],"precision_score_weighted":[0.9015118714810105],"average_precision_score_micro":[0.9627149261051213],"accuracy":[0.8892261001517451],"f1_score_weighted":[0.8382788412929991],"recall_score_weighted":[0.8892261001517451],"AUC_weighted":[0.8714177350249236],"AUC_macro":[0.8714177350249237],"recall_score_micro":[0.8892261001517451],"recall_score_macro":[0.505420054200542],"weighted_accuracy":[0.9845147595835514],"AUC_micro":[0.9618871652225172],"precision_score_macro":[0.9445457307809176],"balanced_accuracy":[0.505420054200542],"f1_score_macro":[0.4813688662195373],"average_precision_score_weighted":[0.9267081274970758],"norm_macro_recall":[0.01084010840108407],"f1_score_micro":[0.8892261001517451],"average_precision_score_macro":[0.7381967609595681],"log_loss":[0.2715933759429978],"matthews_correlation":[0.0981725410784936]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_33":{"log_loss":[0.2939601835508502],"matthews_correlation":[0.20166671366536168],"AUC_weighted":[0.8365786972975676],"f1_score_weighted":[0.8562138878607299],"average_precision_score_weighted":[0.9070074144132912],"recall_score_weighted":[0.8858877086494689],"average_precision_score_macro":[0.6686819119402507],"recall_score_macro":[0.5556421541659026],"f1_score_micro":[0.8858877086494689],"precision_score_macro":[0.682727753850646],"precision_score_micro":[0.8858877086494689],"balanced_accuracy":[0.5556421541659026],"AUC_macro":[0.8365786972975677],"average_precision_score_micro":[0.9506948488461457],"AUC_micro":[0.951908372689572],"weighted_accuracy":[0.9678787468366408],"precision_score_weighted":[0.8508986843849905],"norm_macro_recall":[0.11128430833180514],"recall_score_micro":[0.8858877086494689],"f1_score_macro":[0.5709659188501837],"accuracy":[0.8858877086494689]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_6":{"weighted_accuracy":[0.9784378216750137],"precision_score_macro":[0.8029189097002862],"average_precision_score_micro":[0.9690413009141297],"matthews_correlation":[0.3028069455827301],"precision_score_micro":[0.8983308042488619],"AUC_micro":[0.9684822499717924],"balanced_accuracy":[0.5756737557122666],"f1_score_micro":[0.8983308042488619],"recall_score_macro":[0.5756737557122666],"precision_score_weighted":[0.8809388055623611],"log_loss":[0.24190339908139688],"AUC_weighted":[0.9028400639440434],"average_precision_score_weighted":[0.9303253864027594],"recall_score_micro":[0.8983308042488619],"f1_score_weighted":[0.8687095123122645],"average_precision_score_macro":[0.7360321570886016],"f1_score_macro":[0.6029493597442646],"AUC_macro":[0.9028400639440435],"accuracy":[0.8983308042488619],"norm_macro_recall":[0.1513475114245333],"recall_score_weighted":[0.8983308042488619]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_20":{"AUC_micro":[0.8047393277624395],"recall_score_micro":[0.7047040971168437],"f1_score_micro":[0.7047040971168437],"accuracy":[0.7047040971168437],"precision_score_micro":[0.7047040971168437],"recall_score_weighted":[0.7047040971168437],"f1_score_macro":[0.5845512548138593],"precision_score_weighted":[0.8757110993587777],"weighted_accuracy":[0.7003048069262952],"AUC_weighted":[0.8479796127421289],"norm_macro_recall":[0.4448473363749357],"average_precision_score_macro":[0.7108676916119376],"precision_score_macro":[0.5971984211851311],"recall_score_macro":[0.7224236681874678],"f1_score_weighted":[0.7579320774824435],"log_loss":[0.546499614687998],"AUC_macro":[0.8479796127421289],"balanced_accuracy":[0.7224236681874678],"average_precision_score_weighted":[0.9167368400937056],"matthews_correlation":[0.29406957939934797],"average_precision_score_micro":[0.7912320752745845]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_27":{"average_precision_score_micro":[0.9781773506641871],"recall_score_weighted":[0.9071320182094081],"f1_score_macro":[0.7437598859833529],"matthews_correlation":[0.4920145541977721],"precision_score_weighted":[0.8997233267319942],"norm_macro_recall":[0.4454502849881541],"precision_score_macro":[0.7717231638418078],"precision_score_micro":[0.9071320182094081],"log_loss":[0.324598065634567],"f1_score_weighted":[0.902536982943453],"AUC_micro":[0.977175515392108],"balanced_accuracy":[0.722725142494077],"average_precision_score_weighted":[0.9487064887366019],"f1_score_micro":[0.9071320182094081],"recall_score_micro":[0.9071320182094081],"recall_score_macro":[0.722725142494077],"average_precision_score_macro":[0.8003998813393158],"accuracy":[0.9071320182094081],"AUC_weighted":[0.9349973233156801],"AUC_macro":[0.9349973233156801],"weighted_accuracy":[0.9529152573279388]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_13":{"matthews_correlation":[0.31835518500993887],"precision_score_weighted":[0.8751118864430104],"recall_score_macro":[0.7276320883509586],"average_precision_score_weighted":[0.8861114453616074],"recall_score_weighted":[0.7581183611532625],"average_precision_score_macro":[0.653335038357453],"recall_score_micro":[0.7581183611532625],"f1_score_micro":[0.7581183611532625],"f1_score_weighted":[0.7976899542269787],"precision_score_macro":[0.611309025626533],"precision_score_micro":[0.7581183611532625],"AUC_micro":[0.7930359375611643],"f1_score_macro":[0.6192339339633243],"accuracy":[0.7581183611532625],"norm_macro_recall":[0.4552641767019172],"AUC_weighted":[0.7755702078551886],"weighted_accuracy":[0.7656872780503486],"log_loss":[0.6153062153170247],"balanced_accuracy":[0.7276320883509586],"average_precision_score_micro":[0.7374672841935197],"AUC_macro":[0.7755702078551885]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_26":{"recall_score_micro":[0.9125948406676783],"precision_score_micro":[0.9125948406676783],"precision_score_macro":[0.7834644232348487],"f1_score_micro":[0.9125948406676783],"AUC_macro":[0.9423697825495001],"average_precision_score_weighted":[0.9516558858697237],"recall_score_macro":[0.75895670439958],"average_precision_score_macro":[0.8096965049514568],"log_loss":[0.19370054320418742],"f1_score_weighted":[0.9106208860084958],"weighted_accuracy":[0.9507390340617803],"average_precision_score_micro":[0.9794040437599212],"norm_macro_recall":[0.5179134087991599],"precision_score_weighted":[0.9090583667022298],"recall_score_weighted":[0.9125948406676783],"AUC_micro":[0.9783902127884941],"AUC_weighted":[0.9423697825495002],"f1_score_macro":[0.7704152731326646],"accuracy":[0.9125948406676783],"balanced_accuracy":[0.75895670439958],"matthews_correlation":[0.5418671898368607]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_28":{"log_loss":[0.23069143427314331],"recall_score_macro":[0.6550226267812918],"average_precision_score_macro":[0.7691985267839925],"f1_score_micro":[0.9004552352048558],"f1_score_macro":[0.6889841999967768],"average_precision_score_micro":[0.9693071884594073],"AUC_micro":[0.9709358687117327],"precision_score_macro":[0.7595096856617476],"balanced_accuracy":[0.6550226267812918],"weighted_accuracy":[0.9613895130367017],"precision_score_weighted":[0.8847782884360708],"recall_score_micro":[0.9004552352048558],"matthews_correlation":[0.40114771915827435],"AUC_macro":[0.9214175497872545],"accuracy":[0.9004552352048558],"precision_score_micro":[0.9004552352048558],"f1_score_weighted":[0.8880020273898788],"average_precision_score_weighted":[0.9402332837233544],"norm_macro_recall":[0.3100452535625835],"AUC_weighted":[0.9214175497872545],"recall_score_weighted":[0.9004552352048558]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_3":{"average_precision_score_weighted":[0.938203786698967],"f1_score_macro":[0.7487843138893182],"AUC_micro":[0.9304702715522898],"f1_score_micro":[0.8670713201820941],"matthews_correlation":[0.5359798365026633],"average_precision_score_macro":[0.7606687190092452],"balanced_accuracy":[0.841080435753093],"average_precision_score_micro":[0.9127276081554115],"norm_macro_recall":[0.682160871506186],"recall_score_weighted":[0.8670713201820941],"recall_score_macro":[0.841080435753093],"weighted_accuracy":[0.8735241537442873],"AUC_weighted":[0.9204765424277619],"precision_score_weighted":[0.9142232219886884],"log_loss":[0.3459591398812969],"precision_score_macro":[0.7105620515166242],"recall_score_micro":[0.8670713201820941],"accuracy":[0.8670713201820941],"f1_score_weighted":[0.8825569256056507],"AUC_macro":[0.9204765424277619],"precision_score_micro":[0.8670713201820941]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_38":{"recall_score_micro":[0.9144157814871017],"f1_score_weighted":[0.9103097006711736],"AUC_micro":[0.9802966282199773],"precision_score_weighted":[0.9079806641683502],"weighted_accuracy":[0.9571673317706867],"average_precision_score_micro":[0.9812096910591481],"f1_score_macro":[0.7644868028055063],"AUC_weighted":[0.946511696832621],"precision_score_micro":[0.9144157814871017],"accuracy":[0.9144157814871017],"precision_score_macro":[0.7937126434457988],"matthews_correlation":[0.5334532097611686],"average_precision_score_weighted":[0.9550879554365818],"f1_score_micro":[0.9144157814871017],"log_loss":[0.18553830337881197],"balanced_accuracy":[0.7422200178939589],"AUC_macro":[0.946511696832621],"average_precision_score_macro":[0.8230966199945846],"norm_macro_recall":[0.4844400357879177],"recall_score_weighted":[0.9144157814871017],"recall_score_macro":[0.7422200178939589]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_10":{"recall_score_weighted":[0.8880121396054628],"precision_score_weighted":[0.788565560086672],"f1_score_weighted":[0.8353395018439429],"f1_score_micro":[0.8880121396054628],"balanced_accuracy":[0.5],"recall_score_macro":[0.5],"precision_score_macro":[0.4440060698027314],"average_precision_score_macro":[0.7269149363855643],"precision_score_micro":[0.8880121396054628],"norm_macro_recall":[0.0],"log_loss":[0.27181601742611666],"average_precision_score_micro":[0.9683147296312862],"AUC_weighted":[0.8984568775968006],"weighted_accuracy":[0.9843450583187134],"accuracy":[0.8880121396054628],"AUC_macro":[0.8984568775968006],"f1_score_macro":[0.4703423886834914],"average_precision_score_weighted":[0.9278206683878111],"AUC_micro":[0.9672624867309415],"matthews_correlation":[0.0],"recall_score_micro":[0.8880121396054628]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_17":{"norm_macro_recall":[0.37291491848616376],"precision_score_macro":[0.735424336119674],"average_precision_score_weighted":[0.9334972216909201],"weighted_accuracy":[0.9471448394546703],"f1_score_micro":[0.8952959028831563],"accuracy":[0.8952959028831563],"AUC_macro":[0.9037569904065412],"average_precision_score_micro":[0.9667534628014494],"f1_score_weighted":[0.8892308417191037],"precision_score_micro":[0.8952959028831563],"balanced_accuracy":[0.6864574592430819],"log_loss":[0.24066703261764225],"AUC_micro":[0.9666638881277329],"recall_score_micro":[0.8952959028831563],"recall_score_weighted":[0.8952959028831563],"average_precision_score_macro":[0.7492685928889261],"AUC_weighted":[0.9037569904065412],"precision_score_weighted":[0.8853295785891365],"recall_score_macro":[0.6864574592430819],"f1_score_macro":[0.7067795311722551],"matthews_correlation":[0.4190304216014092]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_9":{"norm_macro_recall":[0.19263328313392503],"f1_score_macro":[0.6298384193301264],"average_precision_score_macro":[0.7663855388302889],"weighted_accuracy":[0.9744492670825422],"recall_score_micro":[0.8992412746585736],"AUC_weighted":[0.9085870626307084],"recall_score_weighted":[0.8992412746585736],"precision_score_micro":[0.8992412746585736],"precision_score_weighted":[0.8802015217661018],"recall_score_macro":[0.5963166415669625],"average_precision_score_weighted":[0.9378164406794613],"log_loss":[0.2851952537739257],"f1_score_weighted":[0.8748982204951351],"AUC_macro":[0.9085870626307084],"precision_score_macro":[0.7843656002187585],"accuracy":[0.8992412746585736],"f1_score_micro":[0.8992412746585736],"matthews_correlation":[0.33099329050749243],"balanced_accuracy":[0.5963166415669625],"average_precision_score_micro":[0.9709787509744373],"AUC_micro":[0.9701411758746066]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_18":{"AUC_weighted":[0.9032762986549893],"average_precision_score_macro":[0.7585181052096663],"matthews_correlation":[0.48451385554235216],"norm_macro_recall":[0.6755275105724401],"AUC_macro":[0.9032762986549893],"f1_score_micro":[0.8191198786039454],"recall_score_micro":[0.8191198786039454],"precision_score_micro":[0.8191198786039454],"f1_score_macro":[0.7024991152930683],"recall_score_macro":[0.83776375528622],"log_loss":[0.47692836563263397],"balanced_accuracy":[0.83776375528622],"f1_score_weighted":[0.8470455485387847],"recall_score_weighted":[0.8191198786039454],"average_precision_score_weighted":[0.9352555893103098],"AUC_micro":[0.8633916749754191],"accuracy":[0.8191198786039454],"weighted_accuracy":[0.8144911083320677],"precision_score_macro":[0.6737558223303043],"precision_score_weighted":[0.9106556896927646],"average_precision_score_micro":[0.8274588228950455]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_2":{"AUC_weighted":[0.8988569909622541],"precision_score_micro":[0.8974203338391502],"weighted_accuracy":[0.9768406062474211],"precision_score_weighted":[0.8777164622862054],"log_loss":[0.23696696490292218],"balanced_accuracy":[0.577529374063392],"recall_score_micro":[0.8974203338391502],"average_precision_score_macro":[0.7425212824089231],"matthews_correlation":[0.2983868415693299],"AUC_macro":[0.8988569909622541],"precision_score_macro":[0.7870999163133994],"recall_score_macro":[0.577529374063392],"norm_macro_recall":[0.155058748126784],"accuracy":[0.8974203338391502],"average_precision_score_micro":[0.9678558897614449],"recall_score_weighted":[0.8974203338391502],"average_precision_score_weighted":[0.930445554710358],"f1_score_macro":[0.6050393644939358],"f1_score_micro":[0.8974203338391502],"f1_score_weighted":[0.8687494662984201],"AUC_micro":[0.9676851623718283]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_5":{"recall_score_macro":[0.5932768914155307],"f1_score_weighted":[0.8746567304785686],"recall_score_micro":[0.9001517450682853],"log_loss":[0.2369610926670341],"average_precision_score_micro":[0.9705724851775741],"f1_score_macro":[0.6267831475663812],"AUC_weighted":[0.904426161486495],"precision_score_micro":[0.9001517450682853],"accuracy":[0.9001517450682853],"matthews_correlation":[0.33340661446628406],"precision_score_macro":[0.7979300898726163],"AUC_micro":[0.9692617452755243],"average_precision_score_macro":[0.7568281908118732],"norm_macro_recall":[0.1865537828310615],"balanced_accuracy":[0.5932768914155307],"AUC_macro":[0.9044261614864952],"f1_score_micro":[0.9001517450682853],"recall_score_weighted":[0.9001517450682853],"precision_score_weighted":[0.8827113977984437],"weighted_accuracy":[0.9763404704059276],"average_precision_score_weighted":[0.9355812168347215]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_15":{"AUC_micro":[0.9715686387385126],"weighted_accuracy":[0.9825566415337869],"average_precision_score_macro":[0.7706100496169006],"f1_score_macro":[0.5954791399047199],"AUC_weighted":[0.9182138642985884],"precision_score_weighted":[0.8924485886335392],"recall_score_macro":[0.5697651371592322],"f1_score_weighted":[0.8680495263718458],"balanced_accuracy":[0.5697651371592322],"average_precision_score_weighted":[0.9403078947697695],"norm_macro_recall":[0.13953027431846432],"AUC_macro":[0.9182138642985884],"recall_score_weighted":[0.9004552352048558],"recall_score_micro":[0.9004552352048558],"precision_score_macro":[0.858775899023577],"matthews_correlation":[0.3164177605938496],"average_precision_score_micro":[0.97294427220011],"precision_score_micro":[0.9004552352048558],"f1_score_micro":[0.9004552352048558],"accuracy":[0.9004552352048558],"log_loss":[0.21515754999578512]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_30":{"precision_score_micro":[0.8940819423368741],"recall_score_micro":[0.8940819423368741],"average_precision_score_micro":[0.8551437869948799],"weighted_accuracy":[0.9804897583102169],"average_precision_score_weighted":[0.8181263272689955],"precision_score_weighted":[0.8743587116063004],"balanced_accuracy":[0.5460463798076122],"average_precision_score_macro":[0.5381931245735151],"AUC_weighted":[0.554071801825332],"AUC_micro":[0.8960088053587424],"AUC_macro":[0.554071801825332],"precision_score_macro":[0.7948124955525511],"f1_score_micro":[0.8940819423368741],"log_loss":[3.569635236225607],"norm_macro_recall":[0.09209275961522434],"matthews_correlation":[0.23302401715053095],"f1_score_weighted":[0.8569267795878551],"f1_score_macro":[0.5572240945744739],"recall_score_macro":[0.5460463798076122],"accuracy":[0.8940819423368741],"recall_score_weighted":[0.8940819423368741]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_4":{"recall_score_weighted":[0.8971168437025797],"f1_score_micro":[0.8971168437025797],"average_precision_score_micro":[0.9682590012622689],"f1_score_macro":[0.62976607751013],"AUC_macro":[0.9103009741649022],"weighted_accuracy":[0.9715063988069405],"matthews_correlation":[0.3206183489094562],"AUC_micro":[0.9697146317706737],"AUC_weighted":[0.9103009741649023],"precision_score_macro":[0.76361027213031],"recall_score_micro":[0.8971168437025797],"norm_macro_recall":[0.19497746583754294],"average_precision_score_macro":[0.757412252478055],"accuracy":[0.8971168437025797],"precision_score_micro":[0.8971168437025797],"log_loss":[0.36628058879277914],"f1_score_weighted":[0.873914616493735],"precision_score_weighted":[0.8757944007896244],"recall_score_macro":[0.5974887329187715],"balanced_accuracy":[0.5974887329187715],"average_precision_score_weighted":[0.9345354311885673]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_22":{"recall_score_weighted":[0.7474962063732928],"accuracy":[0.7474962063732928],"recall_score_micro":[0.7474962063732928],"AUC_weighted":[0.8255000953973994],"AUC_micro":[0.8291295267349941],"average_precision_score_micro":[0.8060355938367948],"norm_macro_recall":[0.4882994626255217],"f1_score_macro":[0.6182973978771774],"precision_score_micro":[0.7474962063732928],"precision_score_weighted":[0.8810202772366675],"matthews_correlation":[0.33408185941702595],"f1_score_weighted":[0.790629872224891],"log_loss":[0.5643608086414009],"balanced_accuracy":[0.7441497313127609],"weighted_accuracy":[0.7483270456102042],"average_precision_score_weighted":[0.9118205222008157],"AUC_macro":[0.8255000953973995],"precision_score_macro":[0.6142850825510042],"average_precision_score_macro":[0.7090150752440016],"recall_score_macro":[0.7441497313127609],"f1_score_micro":[0.7474962063732927]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_39":{"precision_score_micro":[0.9128983308042489],"AUC_micro":[0.9796656082121945],"average_precision_score_macro":[0.8183378072200103],"recall_score_weighted":[0.9128983308042489],"precision_score_macro":[0.7905852778701549],"precision_score_weighted":[0.9056108300409819],"f1_score_weighted":[0.9081236255221017],"recall_score_macro":[0.7330766865426686],"AUC_macro":[0.9443638660583462],"AUC_weighted":[0.9443638660583462],"average_precision_score_micro":[0.9806105592539995],"recall_score_micro":[0.9128983308042489],"matthews_correlation":[0.5204945868078027],"norm_macro_recall":[0.4661533730853371],"weighted_accuracy":[0.9575431809812253],"log_loss":[0.2013045559674163],"balanced_accuracy":[0.7330766865426686],"average_precision_score_weighted":[0.9537944019747684],"f1_score_macro":[0.7573962007511068],"accuracy":[0.9128983308042489],"f1_score_micro":[0.9128983308042489]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_12":{"weighted_accuracy":[0.9747038189797989],"f1_score_macro":[0.6406256273001004],"AUC_weighted":[0.9158715339716624],"balanced_accuracy":[0.6044467228677755],"log_loss":[0.2505849999201559],"precision_score_macro":[0.7936318850994912],"average_precision_score_macro":[0.7687930807278287],"recall_score_macro":[0.6044467228677755],"accuracy":[0.9010622154779969],"AUC_micro":[0.9717893253446501],"norm_macro_recall":[0.2088934457355509],"AUC_macro":[0.9158715339716623],"average_precision_score_weighted":[0.9388951652908787],"precision_score_weighted":[0.8836087454918393],"f1_score_weighted":[0.8780360928868675],"recall_score_micro":[0.9010622154779969],"matthews_correlation":[0.3502506995175259],"recall_score_weighted":[0.9010622154779969],"f1_score_micro":[0.9010622154779969],"precision_score_micro":[0.9010622154779969],"average_precision_score_micro":[0.9720778207198078]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_11":{"log_loss":[1.0211929660498014],"recall_score_macro":[0.8574656337814233],"accuracy":[0.8330804248861912],"weighted_accuracy":[0.8270262371262448],"f1_score_weighted":[0.8582131282048452],"average_precision_score_weighted":[0.9373299964940656],"f1_score_micro":[0.833080424886191],"precision_score_weighted":[0.9170852212183198],"matthews_correlation":[0.5179179547976207],"average_precision_score_micro":[0.8767943509410265],"recall_score_weighted":[0.8330804248861912],"balanced_accuracy":[0.8574656337814233],"AUC_weighted":[0.9223965308689314],"precision_score_micro":[0.8330804248861912],"AUC_micro":[0.8950067813236132],"average_precision_score_macro":[0.7564909820912248],"precision_score_macro":[0.6875977594434772],"f1_score_macro":[0.7208962000300627],"AUC_macro":[0.9223965308689315],"norm_macro_recall":[0.7149312675628465],"recall_score_micro":[0.8330804248861912]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_24":{"log_loss":[0.18604614409172004],"recall_score_weighted":[0.9089529590288316],"accuracy":[0.9089529590288316],"AUC_micro":[0.9781656577193107],"f1_score_weighted":[0.906156466274463],"f1_score_macro":[0.7571849668386146],"recall_score_macro":[0.7426965417979539],"precision_score_macro":[0.7744847871584888],"precision_score_micro":[0.9089529590288316],"weighted_accuracy":[0.950229930267267],"average_precision_score_weighted":[0.9506180438542482],"f1_score_micro":[0.9089529590288316],"AUC_weighted":[0.9400154117740769],"balanced_accuracy":[0.7426965417979539],"AUC_macro":[0.9400154117740767],"matthews_correlation":[0.5162034816601402],"recall_score_micro":[0.9089529590288316],"norm_macro_recall":[0.4853930835959077],"average_precision_score_micro":[0.9791952221583083],"average_precision_score_macro":[0.8061965437553678],"precision_score_weighted":[0.9040871676607377]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_0":{"AUC_weighted":[0.9450464668693167],"norm_macro_recall":[0.5026785366965085],"f1_score_weighted":[0.9091539479147899],"precision_score_micro":[0.9116843702579667],"recall_score_macro":[0.7513392683482543],"precision_score_weighted":[0.9072720074188747],"AUC_micro":[0.979695082216353],"accuracy":[0.9116843702579667],"matthews_correlation":[0.5323740218566827],"log_loss":[0.17775706110025447],"recall_score_weighted":[0.9116843702579667],"f1_score_micro":[0.9116843702579667],"average_precision_score_macro":[0.8151093723721079],"balanced_accuracy":[0.7513392683482543],"f1_score_macro":[0.7653697272147331],"recall_score_micro":[0.9116843702579667],"precision_score_macro":[0.7819118765348991],"average_precision_score_micro":[0.9806603102489483],"weighted_accuracy":[0.9514937218005303],"average_precision_score_weighted":[0.9531771295804466],"AUC_macro":[0.9450464668693166]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_31":{"accuracy":[0.9083459787556905],"recall_score_micro":[0.9083459787556905],"f1_score_micro":[0.9083459787556905],"recall_score_macro":[0.7151197468912488],"weighted_accuracy":[0.9563188254464979],"precision_score_weighted":[0.8995847208846137],"f1_score_weighted":[0.9025288323944487],"AUC_macro":[0.9352566560525483],"log_loss":[0.3231830443160007],"AUC_micro":[0.9771117778581149],"average_precision_score_micro":[0.9781457707557885],"matthews_correlation":[0.488946245475427],"recall_score_weighted":[0.9083459787556905],"AUC_weighted":[0.9352566560525483],"balanced_accuracy":[0.7151197468912488],"average_precision_score_macro":[0.8007746006054122],"precision_score_macro":[0.7778318057957909],"f1_score_macro":[0.7408501014629837],"norm_macro_recall":[0.4302394937824976],"average_precision_score_weighted":[0.9488385568929543],"precision_score_micro":[0.9083459787556905]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_32":{"AUC_macro":[0.9299421873234455],"f1_score_macro":[0.7077695472616289],"log_loss":[0.2076328919485066],"precision_score_weighted":[0.8962827872684357],"average_precision_score_macro":[0.7929011280124569],"AUC_weighted":[0.9299421873234455],"f1_score_weighted":[0.8960743748083936],"average_precision_score_micro":[0.976712461645216],"recall_score_macro":[0.6658988565278681],"f1_score_micro":[0.909256449165402],"norm_macro_recall":[0.33179771305573613],"precision_score_micro":[0.9092564491654022],"recall_score_micro":[0.9092564491654022],"average_precision_score_weighted":[0.9464768948447547],"recall_score_weighted":[0.9092564491654022],"accuracy":[0.9092564491654022],"matthews_correlation":[0.4488653996513105],"precision_score_macro":[0.8036189507585388],"balanced_accuracy":[0.6658988565278681],"weighted_accuracy":[0.9696755567058042],"AUC_micro":[0.9757031967781229]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_7":{"precision_score_macro":[0.76677317027264],"average_precision_score_weighted":[0.9368817451977167],"weighted_accuracy":[0.9705001484886069],"f1_score_micro":[0.8983308042488619],"accuracy":[0.8983308042488619],"balanced_accuracy":[0.6076453143205389],"AUC_weighted":[0.9193577069058455],"log_loss":[0.23706684001542902],"AUC_macro":[0.9193577069058455],"matthews_correlation":[0.338921122187951],"AUC_micro":[0.970548193450784],"f1_score_macro":[0.6420894911644668],"average_precision_score_micro":[0.9698002398298773],"norm_macro_recall":[0.21529062864107784],"precision_score_weighted":[0.8781984336304404],"f1_score_weighted":[0.8770999063570056],"average_precision_score_macro":[0.7551728871359292],"recall_score_weighted":[0.8983308042488619],"recall_score_micro":[0.8983308042488619],"precision_score_micro":[0.8983308042488619],"recall_score_macro":[0.6076453143205389]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_16":{"recall_score_micro":[0.7044006069802732],"AUC_micro":[0.8407803242600989],"f1_score_weighted":[0.7587253687094343],"recall_score_macro":[0.7873800354544899],"precision_score_macro":[0.6208288712786464],"accuracy":[0.7044006069802732],"precision_score_micro":[0.7044006069802732],"AUC_weighted":[0.8714080100472913],"norm_macro_recall":[0.5747600709089797],"balanced_accuracy":[0.7873800354544899],"weighted_accuracy":[0.6837990594456862],"recall_score_weighted":[0.7044006069802732],"average_precision_score_weighted":[0.9232175405761208],"average_precision_score_micro":[0.8554618660035771],"precision_score_weighted":[0.9001660323100968],"matthews_correlation":[0.3726864919042996],"log_loss":[0.5052607754807897],"AUC_macro":[0.8714080100472912],"f1_score_micro":[0.7044006069802732],"average_precision_score_macro":[0.7186697297853736],"f1_score_macro":[0.6036936547122634]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_19":{"f1_score_weighted":[0.8353395018439429],"f1_score_macro":[0.4703423886834914],"matthews_correlation":[0.0],"precision_score_macro":[0.4440060698027314],"precision_score_weighted":[0.788565560086672],"accuracy":[0.8880121396054628],"AUC_micro":[0.9661915672110915],"log_loss":[0.2720729912145169],"AUC_weighted":[0.8930724816475779],"f1_score_micro":[0.8880121396054628],"recall_score_macro":[0.5],"norm_macro_recall":[0.0],"average_precision_score_micro":[0.9669244400518004],"recall_score_micro":[0.8880121396054628],"recall_score_weighted":[0.8880121396054628],"precision_score_micro":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"average_precision_score_weighted":[0.9248737146110808],"balanced_accuracy":[0.5],"average_precision_score_macro":[0.7179615227777105],"AUC_macro":[0.8930724816475779]},"9173fbdc-372e-4785-b37e-97f45e4d41d7_1":{"AUC_micro":[0.9781770788959222],"recall_score_weighted":[0.9071320182094081],"f1_score_weighted":[0.9021127651963996],"matthews_correlation":[0.488678780261868],"norm_macro_recall":[0.43834549418631563],"precision_score_micro":[0.9071320182094081],"f1_score_macro":[0.7416848907681176],"AUC_macro":[0.9392346349984347],"accuracy":[0.9071320182094081],"balanced_accuracy":[0.7191727470931578],"AUC_weighted":[0.9392346349984347],"average_precision_score_macro":[0.8065229883244922],"recall_score_micro":[0.9071320182094081],"f1_score_micro":[0.9071320182094081],"precision_score_weighted":[0.8991976076061607],"precision_score_macro":[0.7723958081530135],"average_precision_score_micro":[0.9791945367231853],"average_precision_score_weighted":[0.9505970434373063],"log_loss":[0.1874363495858499],"recall_score_macro":[0.7191727470931578],"weighted_accuracy":[0.9537972210153172]}}